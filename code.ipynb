{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295a2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the directory paths for each category\n",
    "marino_directory = \"SheepFaceImages/Marino\"\n",
    "poll_directory = \"SheepFaceImages/Poll Dorset\"\n",
    "Suffolk_directory = \"SheepFaceImages/Suffolk\"\n",
    "WhiteSuffolk_directory = \"SheepFaceImages/White Suffolk\"\n",
    "\n",
    "# Define a function to read images from a directory\n",
    "def read_images_from_directory(directory):\n",
    "    image_data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith((\".jpg\", \".jpeg\", \".png\", \".gif\")):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            image_data.append({\"path\": image_path})\n",
    "    return pd.DataFrame(image_data)\n",
    "\n",
    "# Read images from directories into dataframes\n",
    "marino = read_images_from_directory(marino_directory)\n",
    "poll = read_images_from_directory(poll_directory)\n",
    "Suffolk = read_images_from_directory(Suffolk_directory)\n",
    "WhiteSuffolk = read_images_from_directory(WhiteSuffolk_directory)\n",
    "\n",
    "# Split the dataframes into training and testing sets\n",
    "marino_train, marino_test = train_test_split(marino, test_size=0.2, random_state=0)\n",
    "poll_train, poll_test = train_test_split(poll, test_size=0.2, random_state=0)\n",
    "Suffolk_train, Suffolk_test = train_test_split(Suffolk, test_size=0.2, random_state=0)\n",
    "WhiteSuffolk_train, WhiteSuffolk_test = train_test_split(WhiteSuffolk, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create train and test directories if they don't exist\n",
    "train_directories = [\"SheepFaceImages/Marino_train\", \"SheepFaceImages/Poll_train\", \n",
    "                     \"SheepFaceImages/Suffolk_train\", \"SheepFaceImages/WhiteSuffolk_train\"]\n",
    "test_directories = [\"SheepFaceImages/Marino_test\", \"SheepFaceImages/Poll_test\", \n",
    "                    \"SheepFaceImages/Suffolk_test\", \"SheepFaceImages/WhiteSuffolk_test\"]\n",
    "\n",
    "for directory in train_directories + test_directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Copy the images to the appropriate train and test directories\n",
    "for image in marino_train['path']:\n",
    "    shutil.copy(image, \"SheepFaceImages/Marino_train\")\n",
    "for image in marino_test['path']:\n",
    "    shutil.copy(image, \"SheepFaceImages/Marino_test\")\n",
    "for image in poll_train['path']:\n",
    "    shutil.copy(image, \"SheepFaceImages/Poll_train\")\n",
    "for image in poll_test['path']:\n",
    "    shutil.copy(image, \"SheepFaceImages/Poll_test\")\n",
    "for image in Suffolk_train['path']:\n",
    "    shutil.copy(image, \"SheepFaceImages/Suffolk_train\")\n",
    "for image in Suffolk_test['path']:\n",
    "    shutil.copy(image, \"SheepFaceImages/Suffolk_test\")\n",
    "for image in WhiteSuffolk_train['path']:\n",
    "    shutil.copy(image, \"SheepFaceImages/WhiteSuffolk_train\")\n",
    "for image in WhiteSuffolk_test['path']:\n",
    "    shutil.copy(image, \"SheepFaceImages/WhiteSuffolk_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6dcc65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define source and target directories for combined training and testing sets\n",
    "combined_train_dir = \"SheepFaceImages/train\"\n",
    "combined_test_dir = \"SheepFaceImages/test\"\n",
    "\n",
    "# Create target directories if they don't exist\n",
    "os.makedirs(combined_train_dir, exist_ok=True)\n",
    "os.makedirs(combined_test_dir, exist_ok=True)\n",
    "\n",
    "# Specify the source directories (the original train and test directories)\n",
    "train_directories = [\"SheepFaceImages/Marino_train\", \"SheepFaceImages/Poll_train\",\n",
    "                     \"SheepFaceImages/Suffolk_train\", \"SheepFaceImages/WhiteSuffolk_train\"]\n",
    "test_directories = [\"SheepFaceImages/Marino_test\", \"SheepFaceImages/Poll_test\", \n",
    "                    \"SheepFaceImages/Suffolk_test\", \"SheepFaceImages/WhiteSuffolk_test\"]\n",
    "\n",
    "# Move the source directories to the combined directories\n",
    "for train_directory in train_directories:\n",
    "    folder_name = os.path.basename(train_directory)\n",
    "    target_path = os.path.join(combined_train_dir, folder_name)\n",
    "    shutil.move(train_directory, target_path)\n",
    "\n",
    "for test_directory in test_directories:\n",
    "    folder_name = os.path.basename(test_directory)\n",
    "    target_path = os.path.join(combined_test_dir, folder_name)\n",
    "    shutil.move(test_directory, target_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28b1e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383ada83",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d257ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(keras.layers.Conv2D(32,(3,3),input_shape=(256,256,3),activation=\"relu\"))\n",
    "classifier.add(keras.layers.Conv2D(32,(3,3),activation=\"relu\"))\n",
    "classifier.add(keras.layers.MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d924b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(keras.layers.Flatten())\n",
    "classifier.add(keras.layers.Dense(128,activation=\"relu\"))\n",
    "classifier.add(keras.layers.Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fffc1738",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer=\"Adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfcdbad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 924 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1/255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "\n",
    "training_set=train_datagen.flow_from_directory(\"SheepFaceImages/train/\",\n",
    "                                               target_size=(256,256,),batch_size=5,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fe7f676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 234 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "testing_set=test_datagen.flow_from_directory(\"SheepFaceImages/test/\",\n",
    "                                             target_size=(256,256),batch_size=10,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7c1b7bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "185/185 [==============================] - 368s 2s/step - loss: -45178792.0000 - accuracy: 0.3225 - val_loss: -167773376.0000 - val_accuracy: 0.3600\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 351s 2s/step - loss: -2393147136.0000 - accuracy: 0.3236 - val_loss: -5628568576.0000 - val_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 367s 2s/step - loss: -19123185664.0000 - accuracy: 0.3236 - val_loss: -34259820544.0000 - val_accuracy: 0.4000\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 430s 2s/step - loss: -74127458304.0000 - accuracy: 0.3236 - val_loss: -134093873152.0000 - val_accuracy: 0.2400\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 393s 2s/step - loss: -200843640832.0000 - accuracy: 0.3236 - val_loss: -273766547456.0000 - val_accuracy: 0.3600\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 444s 2s/step - loss: -444529475584.0000 - accuracy: 0.3236 - val_loss: -590611546112.0000 - val_accuracy: 0.2600\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 464s 3s/step - loss: -845377830912.0000 - accuracy: 0.3236 - val_loss: -657925210112.0000 - val_accuracy: 0.4400\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 454s 2s/step - loss: -1445301977088.0000 - accuracy: 0.3236 - val_loss: -1620751548416.0000 - val_accuracy: 0.2600\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 377s 2s/step - loss: -2300412166144.0000 - accuracy: 0.3236 - val_loss: -2373182554112.0000 - val_accuracy: 0.3200\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 345s 2s/step - loss: -3429289164800.0000 - accuracy: 0.3236 - val_loss: -4230948061184.0000 - val_accuracy: 0.2600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x190949ac210>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(training_set,epochs=10,validation_data=testing_set,validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea543ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step\n",
      "The predicted category is: Marino\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def predict_sheep_category(image_path, model):\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(image_path, target_size=(256, 256))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # Make predictions using the model\n",
    "    predictions = model.predict(img)\n",
    "    \n",
    "    # Define class labels\n",
    "    class_labels = [\"Marino\", \"Poll Dorset\", \"Suffolk\", \"White Suffolk\", \"Other\"]\n",
    "    \n",
    "    # Get the predicted class label\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_class = class_labels[predicted_class_index]\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Example usage:\n",
    "image_path = \"SheepFaceImages/Marino/000105MA6.jpg\"\n",
    "predicted_category = predict_sheep_category(image_path, classifier)\n",
    "print(f\"The predicted category is: {predicted_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e32a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
